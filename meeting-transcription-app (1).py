"""
Meeting Transcription & Report Generator - Streamlit App
========================================================
Multi-language support, scalable for 500 concurrent users

Installation:
    pip install streamlit openai-whisper transformers torch fpdf2 pandas python-multipart

Run:
    streamlit run app.py --server.maxUploadSize 500
"""

import streamlit as st
import whisper
import os
import io
import json
from datetime import datetime
from transformers import pipeline
from fpdf import FPDF
import tempfile
import traceback
from pathlib import Path

# ============================================================
# MULTI-LANGUAGE SUPPORT
# ============================================================

TRANSLATIONS = {
    "en": {
        "title": "üéôÔ∏è Meeting Transcription & Report Generator",
        "subtitle": "AI-Powered Meeting Analysis with Outline Method",
        "language": "Language",
        "upload_audio": "Upload Audio File",
        "audio_help": "Supported formats: MP3, WAV, M4A, WebM, MP4, FLAC, OGG (Max 500MB)",
        "meeting_details": "Meeting Details (Optional)",
        "meeting_title": "Meeting Title",
        "meeting_date": "Meeting Date",
        "meeting_time": "Meeting Time",
        "location": "Location",
        "organizer": "Organizer",
        "attendees": "Attendees (comma-separated)",
        "whisper_model": "Whisper Model Size",
        "model_help": "Larger models are more accurate but slower. Base recommended for 500 users.",
        "generate_report": "üöÄ Generate Report",
        "processing": "Processing your meeting...",
        "step_transcribing": "Step 1/6: Transcribing audio",
        "step_summarizing": "Step 2/6: Generating summary",
        "step_insights": "Step 3/6: Extracting insights",
        "step_actions": "Step 4/6: Identifying action items",
        "step_takeaways": "Step 5/6: Identifying key takeaways",
        "step_formatting": "Step 6/6: Formatting report",
        "success": "‚úÖ Report Generated Successfully!",
        "download_section": "üì• Download Report",
        "download_txt": "Download as TXT",
        "download_md": "Download as Markdown",
        "download_pdf": "Download as PDF",
        "download_json": "Download as JSON",
        "error": "‚ùå Error",
        "upload_file_first": "Please upload an audio file first.",
        "preview": "üìä Report Preview",
        "stats": "üìà Statistics",
        "duration": "Duration",
        "segments": "Segments",
        "words": "Words",
        "action_items": "Action Items",
        "takeaways": "Key Takeaways",
    },
    "es": {
        "title": "üéôÔ∏è Transcriptor y Generador de Informes de Reuniones",
        "subtitle": "An√°lisis de Reuniones con IA usando M√©todo de Esquema",
        "language": "Idioma",
        "upload_audio": "Subir Archivo de Audio",
        "audio_help": "Formatos soportados: MP3, WAV, M4A, WebM, MP4, FLAC, OGG (Max 500MB)",
        "meeting_details": "Detalles de la Reuni√≥n (Opcional)",
        "meeting_title": "T√≠tulo de la Reuni√≥n",
        "meeting_date": "Fecha de la Reuni√≥n",
        "meeting_time": "Hora de la Reuni√≥n",
        "location": "Ubicaci√≥n",
        "organizer": "Organizador",
        "attendees": "Asistentes (separados por comas)",
        "whisper_model": "Tama√±o del Modelo Whisper",
        "model_help": "Modelos m√°s grandes son m√°s precisos pero m√°s lentos. Base recomendado para 500 usuarios.",
        "generate_report": "üöÄ Generar Informe",
        "processing": "Procesando su reuni√≥n...",
        "step_transcribing": "Paso 1/6: Transcribiendo audio",
        "step_summarizing": "Paso 2/6: Generando resumen",
        "step_insights": "Paso 3/6: Extrayendo informaci√≥n",
        "step_actions": "Paso 4/6: Identificando acciones",
        "step_takeaways": "Paso 5/6: Identificando puntos clave",
        "step_formatting": "Paso 6/6: Formateando informe",
        "success": "‚úÖ ¬°Informe Generado Exitosamente!",
        "download_section": "üì• Descargar Informe",
        "download_txt": "Descargar como TXT",
        "download_md": "Descargar como Markdown",
        "download_pdf": "Descargar como PDF",
        "download_json": "Descargar como JSON",
        "error": "‚ùå Error",
        "upload_file_first": "Por favor, suba un archivo de audio primero.",
        "preview": "üìä Vista Previa del Informe",
        "stats": "üìà Estad√≠sticas",
        "duration": "Duraci√≥n",
        "segments": "Segmentos",
        "words": "Palabras",
        "action_items": "Items de Acci√≥n",
        "takeaways": "Puntos Clave",
    },
    "fr": {
        "title": "üéôÔ∏è Transcripteur et G√©n√©rateur de Rapports de R√©union",
        "subtitle": "Analyse de R√©unions par IA avec M√©thode de Plan",
        "language": "Langue",
        "upload_audio": "T√©l√©charger un Fichier Audio",
        "audio_help": "Formats support√©s: MP3, WAV, M4A, WebM, MP4, FLAC, OGG (Max 500MB)",
        "meeting_details": "D√©tails de la R√©union (Optionnel)",
        "meeting_title": "Titre de la R√©union",
        "meeting_date": "Date de la R√©union",
        "meeting_time": "Heure de la R√©union",
        "location": "Lieu",
        "organizer": "Organisateur",
        "attendees": "Participants (s√©par√©s par des virgules)",
        "whisper_model": "Taille du Mod√®le Whisper",
        "model_help": "Les grands mod√®les sont plus pr√©cis mais plus lents. Base recommand√© pour 500 utilisateurs.",
        "generate_report": "üöÄ G√©n√©rer le Rapport",
        "processing": "Traitement de votre r√©union...",
        "step_transcribing": "√âtape 1/6: Transcription audio",
        "step_summarizing": "√âtape 2/6: G√©n√©ration du r√©sum√©",
        "step_insights": "√âtape 3/6: Extraction des informations",
        "step_actions": "√âtape 4/6: Identification des actions",
        "step_takeaways": "√âtape 5/6: Identification des points cl√©s",
        "step_formatting": "√âtape 6/6: Formatage du rapport",
        "success": "‚úÖ Rapport G√©n√©r√© avec Succ√®s!",
        "download_section": "üì• T√©l√©charger le Rapport",
        "download_txt": "T√©l√©charger en TXT",
        "download_md": "T√©l√©charger en Markdown",
        "download_pdf": "T√©l√©charger en PDF",
        "download_json": "T√©l√©charger en JSON",
        "error": "‚ùå Erreur",
        "upload_file_first": "Veuillez d'abord t√©l√©charger un fichier audio.",
        "preview": "üìä Aper√ßu du Rapport",
        "stats": "üìà Statistiques",
        "duration": "Dur√©e",
        "segments": "Segments",
        "words": "Mots",
        "action_items": "Actions √† Faire",
        "takeaways": "Points Cl√©s",
    },
    "zh": {
        "title": "üéôÔ∏è ‰ºöËÆÆËΩ¨ÂΩï‰∏éÊä•ÂëäÁîüÊàêÂô®",
        "subtitle": "AIÈ©±Âä®ÁöÑ‰ºöËÆÆÂàÜÊûêÔºàÂ§ßÁ∫≤Ê≥ïÔºâ",
        "language": "ËØ≠Ë®Ä",
        "upload_audio": "‰∏ä‰º†Èü≥È¢ëÊñá‰ª∂",
        "audio_help": "ÊîØÊåÅÊ†ºÂºèÔºöMP3„ÄÅWAV„ÄÅM4A„ÄÅWebM„ÄÅMP4„ÄÅFLAC„ÄÅOGGÔºàÊúÄÂ§ß500MBÔºâ",
        "meeting_details": "‰ºöËÆÆËØ¶ÊÉÖÔºàÂèØÈÄâÔºâ",
        "meeting_title": "‰ºöËÆÆÊ†áÈ¢ò",
        "meeting_date": "‰ºöËÆÆÊó•Êúü",
        "meeting_time": "‰ºöËÆÆÊó∂Èó¥",
        "location": "Âú∞ÁÇπ",
        "organizer": "ÁªÑÁªáËÄÖ",
        "attendees": "ÂèÇ‰∏éËÄÖÔºàÈÄóÂè∑ÂàÜÈöîÔºâ",
        "whisper_model": "WhisperÊ®°ÂûãÂ§ßÂ∞è",
        "model_help": "ËæÉÂ§ßÁöÑÊ®°ÂûãÊõ¥ÂáÜÁ°Æ‰ΩÜÊõ¥ÊÖ¢„ÄÇÊé®Ëçê‰ΩøÁî®BaseÊ®°ÂûãÊîØÊåÅ500Áî®Êà∑„ÄÇ",
        "generate_report": "üöÄ ÁîüÊàêÊä•Âëä",
        "processing": "Ê≠£Âú®Â§ÑÁêÜÊÇ®ÁöÑ‰ºöËÆÆ...",
        "step_transcribing": "Ê≠•È™§1/6ÔºöËΩ¨ÂΩïÈü≥È¢ë",
        "step_summarizing": "Ê≠•È™§2/6ÔºöÁîüÊàêÊëòË¶Å",
        "step_insights": "Ê≠•È™§3/6ÔºöÊèêÂèñËßÅËß£",
        "step_actions": "Ê≠•È™§4/6ÔºöËØÜÂà´Ë°åÂä®È°π",
        "step_takeaways": "Ê≠•È™§5/6ÔºöËØÜÂà´ÂÖ≥ÈîÆË¶ÅÁÇπ",
        "step_formatting": "Ê≠•È™§6/6ÔºöÊ†ºÂºèÂåñÊä•Âëä",
        "success": "‚úÖ Êä•ÂëäÁîüÊàêÊàêÂäüÔºÅ",
        "download_section": "üì• ‰∏ãËΩΩÊä•Âëä",
        "download_txt": "‰∏ãËΩΩTXTÊ†ºÂºè",
        "download_md": "‰∏ãËΩΩMarkdownÊ†ºÂºè",
        "download_pdf": "‰∏ãËΩΩPDFÊ†ºÂºè",
        "download_json": "‰∏ãËΩΩJSONÊ†ºÂºè",
        "error": "‚ùå ÈîôËØØ",
        "upload_file_first": "ËØ∑ÂÖà‰∏ä‰º†Èü≥È¢ëÊñá‰ª∂„ÄÇ",
        "preview": "üìä Êä•ÂëäÈ¢ÑËßà",
        "stats": "üìà ÁªüËÆ°‰ø°ÊÅØ",
        "duration": "Êó∂Èïø",
        "segments": "ÁâáÊÆµ",
        "words": "Â≠óÊï∞",
        "action_items": "Ë°åÂä®È°π",
        "takeaways": "ÂÖ≥ÈîÆË¶ÅÁÇπ",
    },
    "de": {
        "title": "üéôÔ∏è Meeting-Transkriptions- und Berichtsgenerator",
        "subtitle": "KI-gest√ºtzte Meeting-Analyse mit Gliederungsmethode",
        "language": "Sprache",
        "upload_audio": "Audiodatei Hochladen",
        "audio_help": "Unterst√ºtzte Formate: MP3, WAV, M4A, WebM, MP4, FLAC, OGG (Max 500MB)",
        "meeting_details": "Meeting-Details (Optional)",
        "meeting_title": "Meeting-Titel",
        "meeting_date": "Meeting-Datum",
        "meeting_time": "Meeting-Zeit",
        "location": "Ort",
        "organizer": "Organisator",
        "attendees": "Teilnehmer (durch Kommas getrennt)",
        "whisper_model": "Whisper-Modellgr√∂√üe",
        "model_help": "Gr√∂√üere Modelle sind genauer, aber langsamer. Base empfohlen f√ºr 500 Benutzer.",
        "generate_report": "üöÄ Bericht Erstellen",
        "processing": "Ihr Meeting wird verarbeitet...",
        "step_transcribing": "Schritt 1/6: Audio transkribieren",
        "step_summarizing": "Schritt 2/6: Zusammenfassung erstellen",
        "step_insights": "Schritt 3/6: Erkenntnisse extrahieren",
        "step_actions": "Schritt 4/6: Aktionspunkte identifizieren",
        "step_takeaways": "Schritt 5/6: Kernpunkte identifizieren",
        "step_formatting": "Schritt 6/6: Bericht formatieren",
        "success": "‚úÖ Bericht Erfolgreich Erstellt!",
        "download_section": "üì• Bericht Herunterladen",
        "download_txt": "Als TXT Herunterladen",
        "download_md": "Als Markdown Herunterladen",
        "download_pdf": "Als PDF Herunterladen",
        "download_json": "Als JSON Herunterladen",
        "error": "‚ùå Fehler",
        "upload_file_first": "Bitte laden Sie zuerst eine Audiodatei hoch.",
        "preview": "üìä Berichtsvorschau",
        "stats": "üìà Statistiken",
        "duration": "Dauer",
        "segments": "Segmente",
        "words": "W√∂rter",
        "action_items": "Aktionspunkte",
        "takeaways": "Kernpunkte",
    },
    "bn": {
        "title": "üéôÔ∏è ‡¶Æ‡¶ø‡¶ü‡¶ø‡¶Ç ‡¶ü‡ßç‡¶∞‡¶æ‡¶®‡ßç‡¶∏‡¶ï‡ßç‡¶∞‡¶ø‡¶™‡¶∂‡¶® ‡¶ì ‡¶∞‡¶ø‡¶™‡ßã‡¶∞‡ßç‡¶ü ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶ü‡¶∞",
        "subtitle": "‡¶è‡¶Ü‡¶á-‡¶ö‡¶æ‡¶≤‡¶ø‡¶§ ‡¶Æ‡¶ø‡¶ü‡¶ø‡¶Ç ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£ (‡¶Ü‡¶â‡¶ü‡¶≤‡¶æ‡¶á‡¶® ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø)",
        "language": "‡¶≠‡¶æ‡¶∑‡¶æ",
        "upload_audio": "‡¶Ö‡¶°‡¶ø‡¶ì ‡¶´‡¶æ‡¶á‡¶≤ ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®",
        "audio_help": "‡¶∏‡¶Æ‡¶∞‡ßç‡¶•‡¶ø‡¶§ ‡¶´‡¶∞‡ßç‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ü: MP3, WAV, M4A, WebM, MP4, FLAC, OGG (‡¶∏‡¶∞‡ßç‡¶¨‡ßã‡¶ö‡ßç‡¶ö 500MB)",
        "meeting_details": "‡¶Æ‡¶ø‡¶ü‡¶ø‡¶Ç ‡¶¨‡¶ø‡¶¨‡¶∞‡¶£ (‡¶ê‡¶ö‡ßç‡¶õ‡¶ø‡¶ï)",
        "meeting_title": "‡¶Æ‡¶ø‡¶ü‡¶ø‡¶Ç ‡¶∂‡¶ø‡¶∞‡ßã‡¶®‡¶æ‡¶Æ",
        "meeting_date": "‡¶Æ‡¶ø‡¶ü‡¶ø‡¶Ç ‡¶§‡¶æ‡¶∞‡¶ø‡¶ñ",
        "meeting_time": "‡¶Æ‡¶ø‡¶ü‡¶ø‡¶Ç ‡¶∏‡¶Æ‡¶Ø‡¶º",
        "location": "‡¶∏‡ßç‡¶•‡¶æ‡¶®",
        "organizer": "‡¶Ü‡¶Ø‡¶º‡ßã‡¶ú‡¶ï",
        "attendees": "‡¶â‡¶™‡¶∏‡ßç‡¶•‡¶ø‡¶§‡¶ø (‡¶ï‡¶Æ‡¶æ ‡¶¶‡ßç‡¶¨‡¶æ‡¶∞‡¶æ ‡¶™‡ßÉ‡¶•‡¶ï)",
        "whisper_model": "Whisper ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶Ü‡¶ï‡¶æ‡¶∞",
        "model_help": "‡¶¨‡¶°‡¶º ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶Ü‡¶∞‡ßã ‡¶®‡¶ø‡¶∞‡ßç‡¶≠‡ßÅ‡¶≤ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶ß‡ßÄ‡¶∞‡•§ ‡ß´‡ß¶‡ß¶ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞‡¶ï‡¶æ‡¶∞‡ßÄ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø Base ‡¶∏‡ßÅ‡¶™‡¶æ‡¶∞‡¶ø‡¶∂‡¶ï‡ßÉ‡¶§‡•§",
        "generate_report": "üöÄ ‡¶∞‡¶ø‡¶™‡ßã‡¶∞‡ßç‡¶ü ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®",
        "processing": "‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶Æ‡¶ø‡¶ü‡¶ø‡¶Ç ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ‡¶ï‡¶∞‡¶£ ‡¶π‡¶ö‡ßç‡¶õ‡ßá...",
        "step_transcribing": "‡¶ß‡¶æ‡¶™ ‡ßß/‡ß¨: ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶ü‡ßç‡¶∞‡¶æ‡¶®‡ßç‡¶∏‡¶ï‡ßç‡¶∞‡¶ø‡¶™‡¶∂‡¶®",
        "step_summarizing": "‡¶ß‡¶æ‡¶™ ‡ß®/‡ß¨: ‡¶∏‡¶æ‡¶∞‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡ßá‡¶™ ‡¶§‡ßà‡¶∞‡¶ø",
        "step_insights": "‡¶ß‡¶æ‡¶™ ‡ß©/‡ß¨: ‡¶Ö‡¶®‡ßç‡¶§‡¶∞‡ßç‡¶¶‡ßÉ‡¶∑‡ßç‡¶ü‡¶ø ‡¶â‡¶§‡ßç‡¶§‡ßã‡¶≤‡¶®",
        "step_actions": "‡¶ß‡¶æ‡¶™ ‡ß™/‡ß¨: ‡¶ï‡¶∞‡ßç‡¶Æ ‡¶Ü‡¶á‡¶ü‡ßá‡¶Æ ‡¶ö‡¶ø‡¶π‡ßç‡¶®‡¶ø‡¶§‡¶ï‡¶∞‡¶£",
        "step_takeaways": "‡¶ß‡¶æ‡¶™ ‡ß´/‡ß¨: ‡¶Æ‡ßÇ‡¶≤ ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º ‡¶ö‡¶ø‡¶π‡ßç‡¶®‡¶ø‡¶§‡¶ï‡¶∞‡¶£",
        "step_formatting": "‡¶ß‡¶æ‡¶™ ‡ß¨/‡ß¨: ‡¶∞‡¶ø‡¶™‡ßã‡¶∞‡ßç‡¶ü ‡¶´‡¶∞‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ü‡¶ø‡¶Ç",
        "success": "‚úÖ ‡¶∞‡¶ø‡¶™‡ßã‡¶∞‡ßç‡¶ü ‡¶∏‡¶´‡¶≤‡¶≠‡¶æ‡¶¨‡ßá ‡¶§‡ßà‡¶∞‡¶ø ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá!",
        "download_section": "üì• ‡¶∞‡¶ø‡¶™‡ßã‡¶∞‡ßç‡¶ü ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®",
        "download_txt": "TXT ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶°",
        "download_md": "Markdown ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶°",
        "download_pdf": "PDF ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶°",
        "download_json": "JSON ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶°",
        "error": "‚ùå ‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø",
        "upload_file_first": "‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶´‡¶æ‡¶á‡¶≤ ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®‡•§",
        "preview": "üìä ‡¶∞‡¶ø‡¶™‡ßã‡¶∞‡ßç‡¶ü ‡¶™‡ßç‡¶∞‡¶ø‡¶≠‡¶ø‡¶â",
        "stats": "üìà ‡¶™‡¶∞‡¶ø‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ‡¶®",
        "duration": "‡¶∏‡¶Æ‡¶Ø‡¶º‡¶ï‡¶æ‡¶≤",
        "segments": "‡¶Ö‡¶Ç‡¶∂‡¶∏‡¶Æ‡ßÇ‡¶π",
        "words": "‡¶∂‡¶¨‡ßç‡¶¶",
        "action_items": "‡¶ï‡¶∞‡ßç‡¶Æ ‡¶Ü‡¶á‡¶ü‡ßá‡¶Æ",
        "takeaways": "‡¶Æ‡ßÇ‡¶≤ ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º",
    }
}

def t(key, lang="en"):
    """Translation helper function"""
    return TRANSLATIONS.get(lang, TRANSLATIONS["en"]).get(key, key)


# ============================================================
# OPTIMIZED TRANSCRIPTION MODULE (For Concurrent Users)
# ============================================================

@st.cache_resource
def load_whisper_model(model_size="base"):
    """Load and cache Whisper model - shared across users"""
    return whisper.load_model(model_size)

class AudioTranscriber:
    """Handles audio transcription with progress tracking"""
    
    @staticmethod
    def transcribe(audio_path, model_size="base", progress_callback=None):
        """Transcribe with progress updates"""
        model = load_whisper_model(model_size)
        
        if progress_callback:
            progress_callback(0.3, "Loading audio file...")
        
        result = model.transcribe(audio_path, verbose=False)
        
        if progress_callback:
            progress_callback(1.0, "Transcription complete")
        
        return result
    
    @staticmethod
    def format_timestamp(seconds):
        """Convert seconds to HH:MM:SS format"""
        hours = int(seconds // 3600)
        mins = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        if hours > 0:
            return f"{hours:02d}:{mins:02d}:{secs:02d}"
        return f"{mins:02d}:{secs:02d}"


# ============================================================
# OPTIMIZED AI ANALYSIS MODULE
# ============================================================

@st.cache_resource
def load_ai_models():
    """Load and cache all AI models - shared across users"""
    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
    qa_model = pipeline("question-answering", model="distilbert-base-cased-distilled-squad")
    classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
    return summarizer, qa_model, classifier

class MeetingAnalyzer:
    """Analyzes meeting transcripts with caching"""
    
    def __init__(self):
        self.summarizer, self.qa_model, self.classifier = load_ai_models()
    
    def summarize_text(self, text, max_length=150, progress_callback=None):
        """Generate summary with chunking for long texts"""
        chunk_size = 1024
        chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]
        
        summaries = []
        for i, chunk in enumerate(chunks):
            if len(chunk.split()) > 50:
                if progress_callback:
                    progress = (i + 1) / len(chunks)
                    progress_callback(progress, f"Summarizing chunk {i+1}/{len(chunks)}")
                
                summary = self.summarizer(chunk, max_length=max_length, min_length=30, do_sample=False)
                summaries.append(summary[0]["summary_text"])
        
        return " ".join(summaries)
    
    def extract_insights(self, text, progress_callback=None):
        """Extract key insights using Q&A"""
        questions = {
            "objective": "What is the main purpose or goal of this meeting?",
            "decisions": "What decisions were made in this meeting?",
            "concerns": "What problems, issues, or concerns were discussed?",
            "next_steps": "What are the next steps or follow-up actions?",
            "deadlines": "What deadlines or dates were mentioned?",
            "owners": "Who is responsible for tasks or action items?"
        }
        
        insights = {}
        context = text[:4096]
        
        for i, (key, question) in enumerate(questions.items()):
            if progress_callback:
                progress = (i + 1) / len(questions)
                progress_callback(progress, f"Extracting: {key}")
            
            try:
                answer = self.qa_model(question=question, context=context)
                insights[key] = answer["answer"] if answer["score"] > 0.1 else "Not clearly identified"
            except:
                insights[key] = "Not identified"
        
        return insights
    
    def extract_action_items(self, text, progress_callback=None):
        """Extract and prioritize action items"""
        action_keywords = [
            "need to", "should", "will", "must", "have to",
            "action item", "follow up", "deadline", "by next",
            "responsible", "assigned to", "take care of"
        ]
        
        sentences = text.replace("?", ".").replace("!", ".").split(".")
        
        potential_actions = []
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 20:
                lower = sentence.lower()
                if any(kw in lower for kw in action_keywords):
                    potential_actions.append(sentence)
        
        priority_labels = ["urgent high priority", "medium priority", "low priority"]
        prioritized = []
        
        for i, action in enumerate(potential_actions[:10]):
            if progress_callback:
                progress = (i + 1) / min(len(potential_actions), 10)
                progress_callback(progress, f"Analyzing action {i+1}")
            
            try:
                result = self.classifier(action, priority_labels)
                priority = "HIGH" if "urgent" in result["labels"][0] or "high" in result["labels"][0] else \
                          "MEDIUM" if "medium" in result["labels"][0] else "LOW"
                
                prioritized.append({
                    "task": action,
                    "priority": priority,
                    "confidence": result["scores"][0]
                })
            except:
                prioritized.append({"task": action, "priority": "MEDIUM", "confidence": 0.5})
        
        priority_order = {"HIGH": 0, "MEDIUM": 1, "LOW": 2}
        prioritized.sort(key=lambda x: priority_order.get(x["priority"], 1))
        
        return prioritized
    
    def identify_key_takeaways(self, text, num_takeaways=5, progress_callback=None):
        """Identify most important points"""
        sentences = text.replace("?", ".").replace("!", ".").split(".")
        sentences = [s.strip() for s in sentences if len(s.strip()) > 30]
        
        importance_labels = ["very important key point", "moderately important", "not important"]
        scored = []
        
        for i, sentence in enumerate(sentences[:30]):
            if progress_callback:
                progress = (i + 1) / min(len(sentences), 30)
                progress_callback(progress, f"Analyzing sentence {i+1}")
            
            try:
                result = self.classifier(sentence, importance_labels)
                if result["labels"][0] == "very important key point":
                    scored.append({"text": sentence, "score": result["scores"][0]})
            except:
                continue
        
        scored.sort(key=lambda x: x["score"], reverse=True)
        return [item["text"] for item in scored[:num_takeaways]]


# ============================================================
# REPORT GENERATOR WITH MULTIPLE FORMAT SUPPORT
# ============================================================

class ReportGenerator:
    """Generates reports in multiple formats"""
    
    PRIORITY_SYMBOLS = {"HIGH": "üî¥", "MEDIUM": "üü°", "LOW": "üü¢"}
    
    def __init__(self, lang="en"):
        self.lang = lang
    
    def generate_text_report(self, meeting_info, summary, insights, action_items, takeaways, transcription):
        """Generate text format report"""
        separator = "‚îÄ" * 70
        
        report = f"""
{'='*70}
                         MEETING REPORT
                     (Outline Method Format)
{'='*70}

{separator}
üìã MEETING BASICS
{separator}

    üìå Title:       {meeting_info.get('title', 'N/A')}
    üìÖ Date:        {meeting_info.get('date', 'N/A')}
    üïê Time:        {meeting_info.get('time', 'N/A')}
    üìç Location:    {meeting_info.get('location', 'N/A')}
    üë§ Organizer:   {meeting_info.get('organizer', 'N/A')}
    üë• Attendees:   {meeting_info.get('attendees', 'N/A')}

{separator}
üéØ MEETING OBJECTIVE
{separator}

    {insights.get('objective', 'Not identified')}

{separator}
üìù EXECUTIVE SUMMARY
{separator}

    {self._wrap_text(summary, 66)}

{separator}
‚≠ê KEY TAKEAWAYS
{separator}

"""
        if takeaways:
            for i, takeaway in enumerate(takeaways, 1):
                report += f"    {i}. {self._wrap_text(takeaway, 62)}\n\n"
        else:
            report += "    No key takeaways identified.\n"
        
        report += f"""
{separator}
‚úÖ DECISIONS MADE
{separator}

    {insights.get('decisions', 'No decisions identified')}

{separator}
‚ö†Ô∏è CONCERNS & ISSUES RAISED
{separator}

    {insights.get('concerns', 'No concerns identified')}

{separator}
üìã ACTION ITEMS (Prioritized)
{separator}

    Legend: üî¥ High Priority  üü° Medium Priority  üü¢ Low Priority

"""
        if action_items:
            for i, item in enumerate(action_items, 1):
                symbol = self.PRIORITY_SYMBOLS.get(item["priority"], "‚ö™")
                priority = item["priority"]
                task = item["task"]
                report += f"    {symbol} [{priority:6}] {i}. {task}\n\n"
        else:
            report += "    No specific action items identified.\n"
        
        report += f"""
{separator}
üìÖ NEXT STEPS & FOLLOW-UPS
{separator}

    {insights.get('next_steps', 'Not identified')}

    üìÖ Deadlines: {insights.get('deadlines', 'None identified')}
    üë§ Owners:    {insights.get('owners', 'Not identified')}

{separator}
üìú FULL TRANSCRIPT (With Timestamps)
{separator}

"""
        for segment in transcription["segments"]:
            start = AudioTranscriber.format_timestamp(segment["start"])
            end = AudioTranscriber.format_timestamp(segment["end"])
            text = segment["text"].strip()
            report += f"    [{start} ‚Üí {end}]  {text}\n"
        
        report += f"""
{'='*70}
                       END OF MEETING REPORT
               Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
{'='*70}
"""
        return report
    
    def generate_json_report(self, meeting_info, summary, insights, action_items, takeaways, transcription):
        """Generate JSON format report"""
        return json.dumps({
            "meeting_info": meeting_info,
            "summary": summary,
            "insights": insights,
            "action_items": action_items,
            "takeaways": takeaways,
            "transcript": {
                "text": transcription["text"],
                "segments": transcription["segments"]
            },
            "generated_at": datetime.now().isoformat()
        }, indent=2, ensure_ascii=False)
    
    def generate_pdf_report(self, meeting_info, summary, insights, action_items, takeaways):
        """Generate PDF format report with proper error handling"""
        try:
            pdf = FPDF()
            pdf.add_page()
            pdf.set_auto_page_break(auto=True, margin=15)
            pdf.set_left_margin(10)
            pdf.set_right_margin(10)
            
            # Title
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "MEETING REPORT", ln=True, align="C")
            pdf.ln(5)
            
            # Meeting Info
            pdf.set_font("Arial", "B", 12)
            pdf.cell(0, 10, "Meeting Details", ln=True)
            pdf.set_font("Arial", "", 10)
            
            # Safely encode text for PDF (Latin-1 compatible only)
            def safe_encode(text):
                """Convert text to Latin-1 safe format"""
                if not text:
                    return "N/A"
                try:
                    # Try to encode as latin-1, replace unsupported chars
                    return text.encode('latin-1', errors='replace').decode('latin-1')
                except:
                    return str(text).encode('ascii', errors='ignore').decode('ascii')
            
            meeting_details = (
                f"Title: {safe_encode(meeting_info.get('title', 'N/A'))}\n"
                f"Date: {safe_encode(meeting_info.get('date', 'N/A'))}\n"
                f"Time: {safe_encode(meeting_info.get('time', 'N/A'))}\n"
                f"Location: {safe_encode(meeting_info.get('location', 'N/A'))}\n"
                f"Organizer: {safe_encode(meeting_info.get('organizer', 'N/A'))}\n"
                f"Attendees: {safe_encode(meeting_info.get('attendees', 'N/A'))}"
            )
            pdf.multi_cell(0, 5, meeting_details)
            pdf.ln(5)
            
            # Summary
            pdf.set_font("Arial", "B", 12)
            pdf.cell(0, 10, "Executive Summary", ln=True)
            pdf.set_font("Arial", "", 10)
            safe_summary = safe_encode(summary)
            if len(safe_summary) > 500:
                safe_summary = safe_summary[:497] + "..."
            pdf.multi_cell(0, 5, safe_summary)
            pdf.ln(5)
            
            # Key Takeaways
            if takeaways:
                pdf.set_font("Arial", "B", 12)
                pdf.cell(0, 10, "Key Takeaways", ln=True)
                pdf.set_font("Arial", "", 10)
                for i, takeaway in enumerate(takeaways, 1):
                    safe_takeaway = safe_encode(takeaway)
                    # Limit length to prevent overflow
                    if len(safe_takeaway) > 200:
                        safe_takeaway = safe_takeaway[:197] + "..."
                    pdf.multi_cell(0, 5, f"{i}. {safe_takeaway}")
                    pdf.ln(2)
                pdf.ln(3)
            
            # Action Items
            if action_items:
                pdf.set_font("Arial", "B", 12)
                pdf.cell(0, 10, "Action Items", ln=True)
                pdf.set_font("Arial", "", 10)
                for i, item in enumerate(action_items, 1):
                    priority = item["priority"]
                    task = safe_encode(item["task"])
                    # Limit length to prevent overflow
                    if len(task) > 200:
                        task = task[:197] + "..."
                    pdf.multi_cell(0, 5, f"[{priority}] {i}. {task}")
                    pdf.ln(2)
                pdf.ln(3)
            
            # Insights
            pdf.set_font("Arial", "B", 12)
            pdf.cell(0, 10, "Key Insights", ln=True)
            pdf.set_font("Arial", "", 10)
            
            for key in ["objective", "decisions", "concerns", "next_steps"]:
                value = safe_encode(insights.get(key, "Not identified"))
                if len(value) > 300:
                    value = value[:297] + "..."
                pdf.multi_cell(0, 5, f"{key.replace('_', ' ').title()}: {value}")
                pdf.ln(2)
            
            return pdf.output(dest='S').encode('latin-1', errors='replace')
            
        except Exception as e:
            # If PDF generation fails, create a simple error PDF
            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "PDF Generation Error", ln=True, align="C")
            pdf.ln(10)
            pdf.set_font("Arial", "", 12)
            pdf.multi_cell(0, 10, f"Unable to generate PDF report.\nError: {str(e)}\n\nPlease use TXT or Markdown format instead.")
            return pdf.output(dest='S').encode('latin-1', errors='replace')
    
    def _wrap_text(self, text, width):
        """Wrap text to specified width"""
        if not text:
            return "N/A"
        
        words = text.split()
        lines = []
        current_line = []
        current_length = 0
        
        for word in words:
            if current_length + len(word) + 1 <= width:
                current_line.append(word)
                current_length += len(word) + 1
            else:
                if current_line:
                    lines.append(" ".join(current_line))
                current_line = [word]
                current_length = len(word)
        
        if current_line:
            lines.append(" ".join(current_line))
        
        return "\n    ".join(lines)


# ============================================================
# STREAMLIT APP
# ============================================================

def main():
    # Page config
    st.set_page_config(
        page_title="Meeting Transcription & Report Generator",
        page_icon="üéôÔ∏è",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Initialize session state
    if "report_generated" not in st.session_state:
        st.session_state.report_generated = False
    if "report_data" not in st.session_state:
        st.session_state.report_data = None
    
    # Sidebar - Language Selection
    st.sidebar.title("‚öôÔ∏è Settings")
    lang = st.sidebar.selectbox(
        "üåç " + t("language", "en"),
        options=["en", "es", "fr", "zh", "de", "bn"],
        format_func=lambda x: {"en": "English", "es": "Espa√±ol", "fr": "Fran√ßais", "zh": "‰∏≠Êñá", "de": "Deutsch", "bn": "‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ"}[x]
    )
    
    # Main title
    st.title(t("title", lang))
    st.markdown(f"**{t('subtitle', lang)}**")
    st.markdown("---")
    
    # File upload
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader(t("upload_audio", lang))
        audio_file = st.file_uploader(
            t("audio_help", lang),
            type=["mp3", "wav", "m4a", "webm", "mp4", "flac", "ogg"],
            help=t("audio_help", lang)
        )
        
        # FFmpeg warning
        if audio_file and not audio_file.name.endswith('.wav'):
            st.warning("‚ö†Ô∏è Non-WAV files require FFmpeg. Install FFmpeg or use WAV format for best results.")
    
    with col2:
        st.subheader(t("whisper_model", lang))
        model_size = st.selectbox(
            t("model_help", lang),
            options=["tiny", "base", "small", "medium"],
            index=1,
            help=t("model_help", lang)
        )
    
    # Meeting details
    st.markdown("---")
    st.subheader(t("meeting_details", lang))
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        meeting_title = st.text_input(t("meeting_title", lang), value="Weekly Team Sync")
        meeting_date = st.date_input(t("meeting_date", lang), value=datetime.now())
        meeting_time = st.time_input(t("meeting_time", lang), value=datetime.now().time())
    
    with col2:
        location = st.text_input(t("location", lang), value="Zoom Meeting")
        organizer = st.text_input(t("organizer", lang), value="")
    
    with col3:
        attendees = st.text_area(
            t("attendees", lang),
            value="",
            height=100,
            help="Separate multiple attendees with commas"
        )
    
    # Generate button
    st.markdown("---")
    if st.button(t("generate_report", lang), type="primary", use_container_width=True):
        if audio_file is None:
            st.error(t("upload_file_first", lang))
        else:
            # Prepare meeting info
            meeting_info = {
                "title": meeting_title,
                "date": meeting_date.strftime("%Y-%m-%d"),
                "time": meeting_time.strftime("%H:%M"),
                "location": location,
                "organizer": organizer if organizer else "Not specified",
                "attendees": attendees if attendees else "Not specified"
            }
            
            # Process the audio
            try:
                # Save uploaded file temporarily
                with tempfile.NamedTemporaryFile(delete=False, suffix=Path(audio_file.name).suffix) as tmp_file:
                    tmp_file.write(audio_file.read())
                    tmp_path = tmp_file.name
                
                # Progress tracking
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Step 1: Transcription
                status_text.text(t("step_transcribing", lang))
                progress_bar.progress(0.15)
                
                transcription = AudioTranscriber.transcribe(
                    tmp_path,
                    model_size=model_size,
                    progress_callback=lambda p, m: progress_bar.progress(0.15 + p * 0.15)
                )
                transcript_text = transcription["text"]
                
                # Initialize analyzer
                analyzer = MeetingAnalyzer()
                
                # Step 2: Summary
                status_text.text(t("step_summarizing", lang))
                progress_bar.progress(0.35)
                
                summary = analyzer.summarize_text(
                    transcript_text,
                    progress_callback=lambda p, m: progress_bar.progress(0.35 + p * 0.15)
                )
                
                # Step 3: Insights
                status_text.text(t("step_insights", lang))
                progress_bar.progress(0.50)
                
                insights = analyzer.extract_insights(
                    transcript_text,
                    progress_callback=lambda p, m: progress_bar.progress(0.50 + p * 0.15)
                )
                
                # Step 4: Action Items
                status_text.text(t("step_actions", lang))
                progress_bar.progress(0.65)
                
                action_items = analyzer.extract_action_items(
                    transcript_text,
                    progress_callback=lambda p, m: progress_bar.progress(0.65 + p * 0.15)
                )
                
                # Step 5: Key Takeaways
                status_text.text(t("step_takeaways", lang))
                progress_bar.progress(0.80)
                
                takeaways = analyzer.identify_key_takeaways(
                    transcript_text,
                    progress_callback=lambda p, m: progress_bar.progress(0.80 + p * 0.15)
                )
                
                # Step 6: Generate Reports
                status_text.text(t("step_formatting", lang))
                progress_bar.progress(0.95)
                
                generator = ReportGenerator(lang)
                
                # Generate all formats
                text_report = generator.generate_text_report(
                    meeting_info, summary, insights, action_items, takeaways, transcription
                )
                
                json_report = generator.generate_json_report(
                    meeting_info, summary, insights, action_items, takeaways, transcription
                )
                
                # Try to generate PDF, but don't fail if it doesn't work
                try:
                    pdf_report = generator.generate_pdf_report(
                        meeting_info, summary, insights, action_items, takeaways
                    )
                    pdf_available = True
                except Exception as pdf_error:
                    st.warning(f"‚ö†Ô∏è PDF generation failed: {str(pdf_error)}. PDF download will be unavailable.")
                    pdf_report = None
                    pdf_available = False
                
                # Store in session state
                st.session_state.report_data = {
                    "text": text_report,
                    "json": json_report,
                    "pdf": pdf_report,
                    "pdf_available": pdf_available,
                    "meeting_info": meeting_info,
                    "summary": summary,
                    "insights": insights,
                    "action_items": action_items,
                    "takeaways": takeaways,
                    "transcription": transcription,
                    "stats": {
                        "duration": AudioTranscriber.format_timestamp(transcription["segments"][-1]["end"]),
                        "segments": len(transcription["segments"]),
                        "words": len(transcript_text.split()),
                        "action_items": len(action_items),
                        "takeaways": len(takeaways)
                    }
                }
                st.session_state.report_generated = True
                
                # Complete
                progress_bar.progress(1.0)
                status_text.text("")
                progress_bar.empty()
                
                # Clean up temp file
                os.unlink(tmp_path)
                
                st.success(t("success", lang))
                st.rerun()
                
            except Exception as e:
                st.error(f"{t('error', lang)}: {str(e)}")
                st.code(traceback.format_exc())
                # Clean up temp file if exists
                try:
                    os.unlink(tmp_path)
                except:
                    pass
    
    # Display report if generated
    if st.session_state.report_generated and st.session_state.report_data:
        st.markdown("---")
        
        # Statistics
        st.subheader(t("stats", lang))
        stats = st.session_state.report_data["stats"]
        
        col1, col2, col3, col4, col5 = st.columns(5)
        col1.metric(t("duration", lang), stats["duration"])
        col2.metric(t("segments", lang), stats["segments"])
        col3.metric(t("words", lang), stats["words"])
        col4.metric(t("action_items", lang), stats["action_items"])
        col5.metric(t("takeaways", lang), stats["takeaways"])
        
        # Download section
        st.markdown("---")
        st.subheader(t("download_section", lang))
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.download_button(
                label=t("download_txt", lang),
                data=st.session_state.report_data["text"],
                file_name=f"meeting_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain",
                use_container_width=True
            )
        
        with col2:
            st.download_button(
                label=t("download_md", lang),
                data=st.session_state.report_data["text"],
                file_name=f"meeting_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                mime="text/markdown",
                use_container_width=True
            )
        
        with col3:
            if st.session_state.report_data.get("pdf_available", False):
                st.download_button(
                    label=t("download_pdf", lang),
                    data=st.session_state.report_data["pdf"],
                    file_name=f"meeting_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                    mime="application/pdf",
                    use_container_width=True
                )
            else:
                st.button(
                    label="‚ö†Ô∏è PDF Unavailable",
                    disabled=True,
                    use_container_width=True,
                    help="PDF generation failed. Please use TXT or Markdown format."
                )
        
        with col4:
            st.download_button(
                label=t("download_json", lang),
                data=st.session_state.report_data["json"],
                file_name=f"meeting_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True
            )
        
        # Report preview
        st.markdown("---")
        st.subheader(t("preview", lang))
        
        # Tabs for different views
        tab1, tab2, tab3, tab4 = st.tabs(["üìù Summary", "üìã Action Items", "‚≠ê Takeaways", "üìú Transcript"])
        
        with tab1:
            st.markdown("### üéØ Meeting Objective")
            st.info(st.session_state.report_data["insights"].get("objective", "Not identified"))
            
            st.markdown("### üìù Executive Summary")
            st.write(st.session_state.report_data["summary"])
            
            st.markdown("### ‚úÖ Decisions Made")
            st.write(st.session_state.report_data["insights"].get("decisions", "No decisions identified"))
            
            st.markdown("### ‚ö†Ô∏è Concerns & Issues")
            st.write(st.session_state.report_data["insights"].get("concerns", "No concerns identified"))
        
        with tab2:
            st.markdown("### üìã Prioritized Action Items")
            
            if st.session_state.report_data["action_items"]:
                for i, item in enumerate(st.session_state.report_data["action_items"], 1):
                    priority = item["priority"]
                    symbol = ReportGenerator.PRIORITY_SYMBOLS.get(priority, "‚ö™")
                    
                    if priority == "HIGH":
                        st.error(f"{symbol} **[{priority}]** {i}. {item['task']}")
                    elif priority == "MEDIUM":
                        st.warning(f"{symbol} **[{priority}]** {i}. {item['task']}")
                    else:
                        st.success(f"{symbol} **[{priority}]** {i}. {item['task']}")
            else:
                st.info("No specific action items identified.")
            
            st.markdown("### üìÖ Next Steps & Follow-ups")
            st.write(st.session_state.report_data["insights"].get("next_steps", "Not identified"))
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**üìÖ Deadlines:**")
                st.write(st.session_state.report_data["insights"].get("deadlines", "None identified"))
            with col2:
                st.markdown("**üë§ Owners/Assignees:**")
                st.write(st.session_state.report_data["insights"].get("owners", "Not identified"))
        
        with tab3:
            st.markdown("### ‚≠ê Key Takeaways")
            
            if st.session_state.report_data["takeaways"]:
                for i, takeaway in enumerate(st.session_state.report_data["takeaways"], 1):
                    st.markdown(f"**{i}.** {takeaway}")
            else:
                st.info("No key takeaways identified.")
        
        with tab4:
            st.markdown("### üìú Full Transcript with Timestamps")
            
            # Display transcript in expandable sections
            transcript_text = ""
            for segment in st.session_state.report_data["transcription"]["segments"]:
                start = AudioTranscriber.format_timestamp(segment["start"])
                end = AudioTranscriber.format_timestamp(segment["end"])
                text = segment["text"].strip()
                transcript_text += f"**[{start} ‚Üí {end}]** {text}\n\n"
            
            st.markdown(transcript_text)
        
        # Full report in expander
        with st.expander("üìÑ View Full Text Report"):
            st.code(st.session_state.report_data["text"], language=None)
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: gray; padding: 20px;'>
        <p>üéôÔ∏è <b>Meeting Transcription & Report Generator</b></p>
        <p>Powered by OpenAI Whisper & HuggingFace Transformers</p>
        <p>Optimized for 500 concurrent users with model caching and efficient resource management</p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()